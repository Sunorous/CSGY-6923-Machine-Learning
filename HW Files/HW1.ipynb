{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f2e59fb-d335-4a90-91bd-017f9f0f295a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db32a3b9-88b1-4550-97b9-286b57a1997c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Labels: [0 1]\n",
      "Labels counts in Y: [50 50]\n",
      "Labels counts in Y_train: [35 35]\n",
      "Labels counts in Y_test: [15 15]\n",
      "Misclassification Perceptron examples: 0\n",
      "Accuracy: 1.000\n"
     ]
    }
   ],
   "source": [
    "# Perceptron train + predict using only parameters petal length and petal width. Linearly separable \n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Perceptron, SGDClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, [2, 3]]\n",
    "Y = iris.target\n",
    "# 0 = Iris-setosa, 1 = Iris-versicolor, 2 = Iris-virginica\n",
    "\n",
    "X = X[Y != 2]  # Exclude class 2 Iris-virginica\n",
    "Y = Y[Y != 2]\n",
    "print('Class Labels:', np.unique(Y))\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=1, stratify=Y)\n",
    "print('Labels counts in Y:', np.bincount(Y))\n",
    "print('Labels counts in Y_train:', np.bincount(Y_train))\n",
    "print('Labels counts in Y_test:', np.bincount(Y_test))\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)\n",
    "\n",
    "ppn = Perceptron(eta0=0.1, random_state=1)\n",
    "ppn.fit(X_train_std, Y_train)\n",
    "\n",
    "Y_pred = ppn.predict(X_test_std)\n",
    "print('Misclassification Perceptron examples: %d' % (Y_test != Y_pred).sum())\n",
    "print('Accuracy: %.3f' % ppn.score(X_test_std, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6099c53e-ca77-4277-a089-59e2c94e77d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassification Adaline examples: 0\n",
      "Accuracy: 1.000\n"
     ]
    }
   ],
   "source": [
    "# Adaline train + predict using only parameters petal length and petal width. Linearly separable \n",
    "\n",
    "ada = SGDClassifier(eta0=0.1, random_state=1)\n",
    "ada.fit(X_train_std, Y_train)\n",
    "Y_pred = ada.predict(X_test_std)\n",
    "print('Misclassification Adaline examples: %d' % (Y_test != Y_pred).sum())\n",
    "print('Accuracy: %.3f' % ada.score(X_test_std, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "995e9e82-cd7a-445e-9749-7defd90855b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Labels: [0 1]\n",
      "Labels counts in Y: [50 50]\n",
      "Labels counts in Y_train: [35 35]\n",
      "Labels counts in Y_test: [15 15]\n",
      "Misclassification Perceptron examples: 0\n",
      "Perceptron Accuracy: 1.000\n",
      "Misclassification Adaline examples: 0\n",
      "Adaline Accuracy: 1.000\n"
     ]
    }
   ],
   "source": [
    "# Repeat with sepal width parameter added\n",
    "\n",
    "X = iris.data[:, [1, 2, 3]]\n",
    "Y = iris.target\n",
    "# 0 = Iris-setosa, 1 = Iris-versicolor, 2 = Iris-virginica\n",
    "\n",
    "X = X[Y != 2]  # Exclude class 2 Iris-virginica\n",
    "Y = Y[Y != 2]\n",
    "print('Class Labels:', np.unique(Y))\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=1, stratify=Y)\n",
    "print('Labels counts in Y:', np.bincount(Y))\n",
    "print('Labels counts in Y_train:', np.bincount(Y_train))\n",
    "print('Labels counts in Y_test:', np.bincount(Y_test))\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)\n",
    "\n",
    "ppn = Perceptron(eta0=0.1, random_state=1)\n",
    "ppn.fit(X_train_std, Y_train)\n",
    "\n",
    "Y_pred = ppn.predict(X_test_std)\n",
    "print('Misclassification Perceptron examples: %d' % (Y_test != Y_pred).sum())\n",
    "print('Perceptron Accuracy: %.3f' % ppn.score(X_test_std, Y_test))\n",
    "\n",
    "ada = SGDClassifier(eta0=0.1, random_state=1)\n",
    "ada.fit(X_train_std, Y_train)\n",
    "Y_pred = ada.predict(X_test_std)\n",
    "print('Misclassification Adaline examples: %d' % (Y_test != Y_pred).sum())\n",
    "print('Adaline Accuracy: %.3f' % ada.score(X_test_std, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93742c6b-02e1-434f-ba3a-49ffb30b75e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Labels: [0 1]\n",
      "Labels counts in Y: [50 50]\n",
      "Labels counts in Y_train: [35 35]\n",
      "Labels counts in Y_test: [15 15]\n",
      "Misclassification Perceptron examples: 0\n",
      "Perceptron Accuracy: 1.000\n",
      "Misclassification Adaline examples: 0\n",
      "Adaline Accuracy: 1.000\n"
     ]
    }
   ],
   "source": [
    "# Repeat with all four parameters\n",
    "\n",
    "X = iris.data\n",
    "Y = iris.target\n",
    "# 0 = Iris-setosa, 1 = Iris-versicolor, 2 = Iris-virginica\n",
    "\n",
    "X = X[Y != 2]  # Exclude class 2 Iris-virginica\n",
    "Y = Y[Y != 2]\n",
    "print('Class Labels:', np.unique(Y))\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=1, stratify=Y)\n",
    "print('Labels counts in Y:', np.bincount(Y))\n",
    "print('Labels counts in Y_train:', np.bincount(Y_train))\n",
    "print('Labels counts in Y_test:', np.bincount(Y_test))\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)\n",
    "\n",
    "ppn = Perceptron(eta0=0.1, random_state=1)\n",
    "ppn.fit(X_train_std, Y_train)\n",
    "\n",
    "Y_pred = ppn.predict(X_test_std)\n",
    "print('Misclassification Perceptron examples: %d' % (Y_test != Y_pred).sum())\n",
    "print('Perceptron Accuracy: %.3f' % ppn.score(X_test_std, Y_test))\n",
    "\n",
    "ada = SGDClassifier(eta0=0.1, random_state=1)\n",
    "ada.fit(X_train_std, Y_train)\n",
    "Y_pred = ada.predict(X_test_std)\n",
    "print('Misclassification Adaline examples: %d' % (Y_test != Y_pred).sum())\n",
    "print('Adaline Accuracy: %.3f' % ada.score(X_test_std, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4975e146-db4d-4141-80e1-fce3880c1ffd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Labels: [1 2]\n",
      "Labels counts in Y: [ 0 50 50]\n",
      "Labels counts in Y_train: [ 0 35 35]\n",
      "Labels counts in Y_test: [ 0 15 15]\n",
      "Misclassification Perceptron examples: 9\n",
      "Perceptron Accuracy: 0.700\n",
      "Misclassification Adaline examples: 12\n",
      "Adaline Accuracy: 0.600\n"
     ]
    }
   ],
   "source": [
    "# Perceptron and Adaline model on classes Versicolor and Virginica and features sepal length and sepal width. Linearly no separable\n",
    "\n",
    "X = iris.data[:, [0, 1]]\n",
    "Y = iris.target\n",
    "# 0 = Iris-setosa, 1 = Iris-versicolor, 2 = Iris-virginica\n",
    "\n",
    "X = X[Y != 0]  # Exclude class 0 Iris-setosa\n",
    "Y = Y[Y != 0]\n",
    "print('Class Labels:', np.unique(Y))\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=1, stratify=Y)\n",
    "print('Labels counts in Y:', np.bincount(Y))\n",
    "print('Labels counts in Y_train:', np.bincount(Y_train))\n",
    "print('Labels counts in Y_test:', np.bincount(Y_test))\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)\n",
    "\n",
    "ppn = Perceptron(eta0=0.1, random_state=1)\n",
    "ppn.fit(X_train_std, Y_train)\n",
    "\n",
    "Y_pred = ppn.predict(X_test_std)\n",
    "print('Misclassification Perceptron examples: %d' % (Y_test != Y_pred).sum())\n",
    "print('Perceptron Accuracy: %.3f' % ppn.score(X_test_std, Y_test))\n",
    "\n",
    "ada = SGDClassifier(eta0=0.1, random_state=1)\n",
    "ada.fit(X_train_std, Y_train)\n",
    "Y_pred = ada.predict(X_test_std)\n",
    "print('Misclassification Adaline examples: %d' % (Y_test != Y_pred).sum())\n",
    "print('Adaline Accuracy: %.3f' % ada.score(X_test_std, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44d735c9-9c9d-47e5-8415-64ba2f5661f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Labels: [1 2]\n",
      "Labels counts in Y: [ 0 50 50]\n",
      "Labels counts in Y_train: [ 0 35 35]\n",
      "Labels counts in Y_test: [ 0 15 15]\n",
      "Misclassification Perceptron examples: 2\n",
      "Perceptron Accuracy: 0.933\n",
      "Misclassification Adaline examples: 2\n",
      "Adaline Accuracy: 0.933\n"
     ]
    }
   ],
   "source": [
    "# Add petal length feature\n",
    "\n",
    "X = iris.data[:, [0, 1, 2]]\n",
    "Y = iris.target\n",
    "# 0 = Iris-setosa, 1 = Iris-versicolor, 2 = Iris-virginica\n",
    "\n",
    "X = X[Y != 0]  # Exclude class 0 Iris-setosa\n",
    "Y = Y[Y != 0]\n",
    "print('Class Labels:', np.unique(Y))\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=1, stratify=Y)\n",
    "print('Labels counts in Y:', np.bincount(Y))\n",
    "print('Labels counts in Y_train:', np.bincount(Y_train))\n",
    "print('Labels counts in Y_test:', np.bincount(Y_test))\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)\n",
    "\n",
    "ppn = Perceptron(eta0=0.1, random_state=1)\n",
    "ppn.fit(X_train_std, Y_train)\n",
    "\n",
    "Y_pred = ppn.predict(X_test_std)\n",
    "print('Misclassification Perceptron examples: %d' % (Y_test != Y_pred).sum())\n",
    "print('Perceptron Accuracy: %.3f' % ppn.score(X_test_std, Y_test))\n",
    "\n",
    "ada = SGDClassifier(eta0=0.1, random_state=1)\n",
    "ada.fit(X_train_std, Y_train)\n",
    "Y_pred = ada.predict(X_test_std)\n",
    "print('Misclassification Adaline examples: %d' % (Y_test != Y_pred).sum())\n",
    "print('Adaline Accuracy: %.3f' % ada.score(X_test_std, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01cdeecd-db5a-44bf-a525-12be957bf32b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Labels: [1 2]\n",
      "Labels counts in Y: [ 0 50 50]\n",
      "Labels counts in Y_train: [ 0 35 35]\n",
      "Labels counts in Y_test: [ 0 15 15]\n",
      "Misclassification Perceptron examples: 1\n",
      "Perceptron Accuracy: 0.967\n",
      "Misclassification Adaline examples: 2\n",
      "Adaline Accuracy: 0.933\n"
     ]
    }
   ],
   "source": [
    "# All four features\n",
    "\n",
    "X = iris.data\n",
    "Y = iris.target\n",
    "# 0 = Iris-setosa, 1 = Iris-versicolor, 2 = Iris-virginica\n",
    "\n",
    "X = X[Y != 0]  # Exclude class 0 Iris-setosa\n",
    "Y = Y[Y != 0]\n",
    "print('Class Labels:', np.unique(Y))\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=1, stratify=Y)\n",
    "print('Labels counts in Y:', np.bincount(Y))\n",
    "print('Labels counts in Y_train:', np.bincount(Y_train))\n",
    "print('Labels counts in Y_test:', np.bincount(Y_test))\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)\n",
    "\n",
    "ppn = Perceptron(eta0=0.1, random_state=1)\n",
    "ppn.fit(X_train_std, Y_train)\n",
    "\n",
    "Y_pred = ppn.predict(X_test_std)\n",
    "print('Misclassification Perceptron examples: %d' % (Y_test != Y_pred).sum())\n",
    "print('Perceptron Accuracy: %.3f' % ppn.score(X_test_std, Y_test))\n",
    "\n",
    "ada = SGDClassifier(eta0=0.1, random_state=1)\n",
    "ada.fit(X_train_std, Y_train)\n",
    "Y_pred = ada.predict(X_test_std)\n",
    "print('Misclassification Adaline examples: %d' % (Y_test != Y_pred).sum())\n",
    "print('Adaline Accuracy: %.3f' % ada.score(X_test_std, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c945ac50-dada-41fd-98b4-022d837361e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The results from Perceptron and Adaline models are very similar except for the 2 classes 2 features not linear separable problem. \n",
    "# I suspect as more features are added. The models become more accurate even when its not linearly separable. Perceptron and Adaline had very similar accuracies when all four features are added on linearly not separable data. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
