{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30a7b914-f366-4546-9868-64e4ed97c12b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f644f1d6-058e-445f-b81f-29872ae94a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the file into a dataframe\n",
    "\n",
    "data = pandas.read_csv('DataSetForPhishingVSBenignUrl.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1ffc635-80e2-4f3f-b109-cae4c1e6054f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree Depth: 1, Criteria Measure: gini\n",
      "Misclassification examples: 2465\n",
      "Train accuracy: 0.669\n",
      "Test accuracy: 0.664\n",
      "\n",
      "Tree Depth: 3, Criteria Measure: gini\n",
      "Misclassification examples: 2214\n",
      "Train accuracy: 0.710\n",
      "Test accuracy: 0.698\n",
      "\n",
      "Tree Depth: 6, Criteria Measure: gini\n",
      "Misclassification examples: 641\n",
      "Train accuracy: 0.935\n",
      "Test accuracy: 0.913\n",
      "\n",
      "Tree Depth: 9, Criteria Measure: gini\n",
      "Misclassification examples: 201\n",
      "Train accuracy: 0.997\n",
      "Test accuracy: 0.973\n",
      "\n",
      "Tree Depth: 12, Criteria Measure: gini\n",
      "Misclassification examples: 153\n",
      "Train accuracy: 1.000\n",
      "Test accuracy: 0.979\n",
      "\n",
      "Tree Depth: 15, Criteria Measure: gini\n",
      "Misclassification examples: 145\n",
      "Train accuracy: 1.000\n",
      "Test accuracy: 0.980\n",
      "\n",
      "Tree Depth: 18, Criteria Measure: gini\n",
      "Misclassification examples: 130\n",
      "Train accuracy: 1.000\n",
      "Test accuracy: 0.982\n",
      "\n",
      "Tree Depth: 1, Criteria Measure: entropy\n",
      "Misclassification examples: 2782\n",
      "Train accuracy: 0.635\n",
      "Test accuracy: 0.621\n",
      "\n",
      "Tree Depth: 3, Criteria Measure: entropy\n",
      "Misclassification examples: 2009\n",
      "Train accuracy: 0.742\n",
      "Test accuracy: 0.726\n",
      "\n",
      "Tree Depth: 6, Criteria Measure: entropy\n",
      "Misclassification examples: 595\n",
      "Train accuracy: 0.939\n",
      "Test accuracy: 0.919\n",
      "\n",
      "Tree Depth: 9, Criteria Measure: entropy\n",
      "Misclassification examples: 202\n",
      "Train accuracy: 0.999\n",
      "Test accuracy: 0.972\n",
      "\n",
      "Tree Depth: 12, Criteria Measure: entropy\n",
      "Misclassification examples: 162\n",
      "Train accuracy: 1.000\n",
      "Test accuracy: 0.978\n",
      "\n",
      "Tree Depth: 15, Criteria Measure: entropy\n",
      "Misclassification examples: 137\n",
      "Train accuracy: 1.000\n",
      "Test accuracy: 0.981\n",
      "\n",
      "Tree Depth: 18, Criteria Measure: entropy\n",
      "Misclassification examples: 216\n",
      "Train accuracy: 1.000\n",
      "Test accuracy: 0.971\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "#Set up features and target sets\n",
    "X = data.drop('URL_Type_obf_Type', axis=1)\n",
    "y = data['URL_Type_obf_Type']\n",
    "\n",
    "#Impute missing values\n",
    "X = np.where(np.isinf(X), 1e10, X)\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X = imputer.fit_transform(X)\n",
    "\n",
    "#Split train and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "#Train model\n",
    "depths = [1, 3, 6, 9, 12, 15, 18]\n",
    "criteria = ['gini', 'entropy']\n",
    "\n",
    "for criterion in criteria:\n",
    "    for depth in depths:\n",
    "        dtc = DecisionTreeClassifier(max_depth=depth, criterion=criterion)\n",
    "        ada = AdaBoostClassifier(dtc)\n",
    "        ada.fit(X_train, y_train)\n",
    "        y_pred = ada.predict(X_test)\n",
    "\n",
    "        #Accuracy\n",
    "        print(f'Tree Depth: {depth}, Criteria Measure: {criterion}')\n",
    "        print('Misclassification examples: %d' % (y_test != y_pred).sum())\n",
    "        print('Train accuracy: %.3f' % ada.score(X_train, y_train))\n",
    "        print('Test accuracy: %.3f' % ada.score(X_test, y_test))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0bba20-0110-4ace-a315-98a891c7749e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The results from AdaBoost is much better compared to just Deision Tree Classifier from last week. At tree depth 6, DTC had around 75% testing accuracy.\n",
    "# With Adaboost, the accuracy at depth 6 is 90%+. The improvement in result is significant. At depth 9 onward, the accuracy tops out to 97%\n",
    "\n",
    "# However, this comes at a cost of runtime and resources. Adaboost took significantly longer to fit compared to DTC. \n",
    "# This is due to the way Adaboost iterates several shallow trees as a part of this learning process. \n",
    "\n",
    "#Overall Adaboost is a much more accuracy classifier compared to DTC. The downside is Adaboost use more resources. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
